# VibeVoice API Configuration
# Copy this file to .env and adjust values as needed

# ============================================================
# Model Configuration
# ============================================================

# Path to VibeVoice model (HuggingFace model ID or local path)
# Use HuggingFace model ID (downloads automatically) or local path to model directory

#VIBEVOICE_MODEL_PATH=microsoft/VibeVoice-1.5B
VIBEVOICE_MODEL_PATH=rsxdalv/VibeVoice-Large # (7B model, requires more VRAM)
#VIBEVOICE_MODEL_PATH=microsoft/VibeVoice-Realtime-0.5B #(smaller, faster)
# Local path example:
# VIBEVOICE_MODEL_PATH=/path/to/your/model

# Device for inference: cuda, cpu, or mps
VIBEVOICE_DEVICE=cuda

# Optional: Specify which GPU to use
# CUDA_VISIBLE_DEVICES=0

# Number of diffusion inference steps (5-50, higher = better quality but slower)
VIBEVOICE_INFERENCE_STEPS=10

# Model dtype: bfloat16, float16, or float32 (auto-detected if not set)
# VIBEVOICE_DTYPE=bfloat16

# Attention implementation: flash_attention_2, sdpa, or eager (auto-detected if not set)
# VIBEVOICE_ATTN_IMPLEMENTATION=flash_attention_2

# Enable torch.compile for optimized inference (20-50% speedup)
# Note: First request will be slower due to compilation, subsequent requests are faster
# TORCH_COMPILE=true

# Quantization method to reduce VRAM usage
# Options:
#   - int8_torchao: Uses torchao INT8 weight-only quantization (~40% VRAM reduction)
#                   Only quantizes the LLM decoder, audio components stay full precision
#                   Requires: pip install torchao
#   - (leave empty or unset for full precision)
# VIBEVOICE_QUANTIZATION=int8_torchao


# ============================================================
# Voice Configuration
# ============================================================

# Directory containing voice preset audio files
# The API automatically loads ALL audio files from this directory as voice presets
# Supported formats: .wav, .mp3, .flac, .ogg, .m4a, .aac
VOICES_DIR=./demo/voices

# OpenAI voice name to VibeVoice preset mapping (JSON format)
# Maps OpenAI-compatible voice names (alloy, echo, fable, onyx, nova, shimmer) to your voice preset files
# Format: {"openai_voice_name": "vibevoice_preset_name", ...}
# Default mapping uses voices from demo/voices folder
OPENAI_VOICE_MAPPING={"alloy": "en-Alice_woman", "echo": "en-Carter_man", "fable": "en-Maya_woman", "onyx": "en-Frank_man", "nova": "en-Mary_woman_bgm", "shimmer": "en-Alice_woman"}


# ============================================================
# API Server Configuration
# ============================================================

API_HOST=0.0.0.0
API_PORT=8001
API_WORKERS=1
API_CORS_ORIGINS=*


# ============================================================
# Generation Defaults
# ============================================================

# Default CFG scale (1.0-3.0, higher = more faithful to prompt)
DEFAULT_CFG_SCALE=1.8

# Default audio response format
DEFAULT_RESPONSE_FORMAT=mp3

# Maximum generation length in seconds
MAX_GENERATION_LENGTH=5400

# Text generation sampling (False = greedy decoding, True = sampling)
DEFAULT_DO_SAMPLE=False

# Sampling parameters (only used if DO_SAMPLE=True)
DEFAULT_TEMPERATURE=1.0
DEFAULT_TOP_P=1.0
DEFAULT_TOP_K=50
DEFAULT_REPETITION_PENALTY=1.0


# ============================================================
# Logging
# ============================================================

LOG_LEVEL=INFO

