# VibeVoice API Configuration
# Copy this file to .env and adjust values as needed

# ============================================================
# Model Configuration
# ============================================================

# Path to VibeVoice model (local path or HuggingFace model ID)
# Option 1: Use HuggingFace model ID (will download automatically)
VIBEVOICE_MODEL_PATH=microsoft/VibeVoice-1.5B
# Option 2: Use local HuggingFace cache path (faster loading)
# VIBEVOICE_MODEL_PATH=~/.cache/huggingface/hub/models--microsoft--VibeVoice-1.5B/snapshots/...
# Option 3: Use custom local path
# VIBEVOICE_MODEL_PATH=/path/to/your/model

# Alternative models:
# microsoft/VibeVoice-Large (7B model, requires more VRAM)
# microsoft/VibeVoice-Realtime-0.5B (smaller, faster)

# Device for inference: cuda, cpu, or mps
VIBEVOICE_DEVICE=cuda

# Optional: Specify which GPU to use (0, 1, 2, etc.)
# CUDA_VISIBLE_DEVICES=0

# Number of diffusion inference steps (5-50, default: 10)
# Higher = better quality but slower
VIBEVOICE_INFERENCE_STEPS=10

# Model dtype: bfloat16, float16, or float32 (auto-detected if not set)
# VIBEVOICE_DTYPE=bfloat16

# Attention implementation: flash_attention_2, sdpa, or eager (auto-detected if not set)
# VIBEVOICE_ATTN_IMPLEMENTATION=flash_attention_2


# ============================================================
# Voice Configuration
# ============================================================

# Directory containing voice preset audio files
# The API automatically loads ALL audio files from this directory as voice presets
# Supported formats: .wav, .mp3, .flac, .ogg, .m4a, .aac
# Just drop audio files here and restart the server - no code changes needed!
VOICES_DIR=demo/voices

# Examples:
# VOICES_DIR=/path/to/my/custom/voices
# VOICES_DIR=./my_company_voices
# VOICES_DIR=/mnt/shared/tts_voices


# ============================================================
# API Server Configuration
# ============================================================

# Server host (0.0.0.0 for all interfaces, 127.0.0.1 for localhost only)
API_HOST=0.0.0.0

# Server port
API_PORT=8001

# Number of API workers (keep at 1 for model loading, increase for CPU-only)
API_WORKERS=1

# CORS allowed origins (comma-separated, or * for all)
API_CORS_ORIGINS=*


# ============================================================
# Generation Defaults
# ============================================================

# Default CFG scale for generation (1.0-3.0, higher = more faithful to prompt)
DEFAULT_CFG_SCALE=1.3

# Default audio response format
DEFAULT_RESPONSE_FORMAT=mp3

# Maximum generation length in seconds (90 minutes = 5400 seconds)
MAX_GENERATION_LENGTH=5400

# Text generation sampling (False = greedy decoding, more deterministic)
DEFAULT_DO_SAMPLE=False

# Temperature for sampling (only used if DO_SAMPLE=True)
# Higher = more random, lower = more focused (0.1-2.0)
DEFAULT_TEMPERATURE=1.0

# Top-p (nucleus) sampling (only used if DO_SAMPLE=True)
# 1.0 = consider all tokens, 0.9 = consider top 90% probability mass
DEFAULT_TOP_P=1.0

# Top-k sampling (only used if DO_SAMPLE=True)
# Limits to top k tokens (1-100)
DEFAULT_TOP_K=50

# Repetition penalty (1.0 = no penalty, higher = less repetition)
DEFAULT_REPETITION_PENALTY=1.0


# ============================================================
# Logging
# ============================================================

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

